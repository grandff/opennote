/// <reference types="chrome"/>

import { MAX_AUDIO_FILE_SIZE } from '@/utils/constants';

let mediaRecorder: MediaRecorder | null = null;
let audioChunks: Blob[] = [];
let audioContext: AudioContext | null = null;
let sourceNode: MediaStreamAudioSourceNode | null = null;
let currentStream: MediaStream | null = null;
let isManualStop: boolean = false;
let finalBlob: Blob | null = null;

// ë¡œê·¸ë¥¼ Backgroundë¡œ ì „ì†¡í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
function logToBackground(message: string, data?: any) {
  const fullMessage = data !== undefined ? `${message} ${JSON.stringify(data)}` : message;
  console.log(fullMessage);
  chrome.runtime.sendMessage({
    type: 'OFFSCREEN_LOG',
    message: fullMessage,
    data: data,
  }).catch(() => {});
}

logToBackground('ğŸŸ¢ Offscreen document loaded');

// Backgroundì— ì¤€ë¹„ ì™„ë£Œ ì‹ í˜¸
setTimeout(() => {
  logToBackground('ğŸŸ¢ Offscreen document fully loaded and ready');
}, 100);

// Backgroundë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
chrome.runtime.onMessage.addListener((message, _sender, sendResponse) => {
  console.log('Offscreen received message:', message);

  switch (message.type) {
    case 'CLEANUP':
      console.log('Offscreen: Received CLEANUP message');
      cleanup();
      sendResponse({ success: true });
      break;

    case 'START_RECORDING':
      (async () => {
        logToBackground('ğŸ”´ START_RECORDING message received');
        
        // ì´ì „ ë…¹ìŒì´ ìˆìœ¼ë©´ ì™„ì „íˆ ì •ë¦¬
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
          logToBackground('âš ï¸ Previous recording still active, cleaning up...');
          try {
            const prevState = mediaRecorder.state;
            logToBackground(`âš ï¸ Previous recorder state: ${prevState}`);
            
            if (prevState === 'recording' || prevState === 'paused') {
              logToBackground('âš ï¸ Stopping previous recorder...');
              mediaRecorder.stop();
              // stop ì™„ë£Œ ëŒ€ê¸°
              await new Promise(resolve => setTimeout(resolve, 200));
            }
          } catch (e) {
            logToBackground('âš ï¸ Error stopping previous recorder:', e);
          }
          
          // ì™„ì „ ì •ë¦¬
          cleanup();
          // ì •ë¦¬ ì™„ë£Œ ëŒ€ê¸°
          await new Promise(resolve => setTimeout(resolve, 300));
        }
        
        // ìŠ¤íŠ¸ë¦¼ì´ ë‚¨ì•„ìˆìœ¼ë©´ ì •ë¦¬
        if (currentStream) {
          logToBackground('âš ï¸ Cleaning up existing stream...');
          currentStream.getTracks().forEach(track => {
            try {
              track.stop();
            } catch (e) {
              logToBackground('âš ï¸ Error stopping track:', e);
            }
          });
          currentStream = null;
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        
        // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ê°€ ë‚¨ì•„ìˆìœ¼ë©´ ì •ë¦¬
        if (audioContext && audioContext.state !== 'closed') {
          logToBackground('âš ï¸ Closing existing audio context...');
          try {
            await audioContext.close();
          } catch (e) {
            logToBackground('âš ï¸ Error closing audio context:', e);
          }
          audioContext = null;
          sourceNode = null;
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        
        try {
          logToBackground('ğŸŸ¢ Starting new recording...');
          await startRecording(message.streamId);
          sendResponse({ success: true });
        } catch (error: any) {
          console.error('Offscreen: âŒ Error starting recording:', error);
          logToBackground(`âŒ Error: ${error.message || 'Unknown error'}`);
          sendResponse({ error: error.message || 'Error starting recording' });
        }
      })();
      return true;

    case 'STOP_RECORDING':
      (async () => {
        try {
          const blob = await stopRecording();
          if (!blob || blob.size === 0) {
            sendResponse({ error: 'No audio data recorded' });
            return;
          }
          
          // Blobì„ ArrayBufferë¡œ ë³€í™˜ í›„ base64ë¡œ ì¸ì½”ë”© (Chrome message passingì„ ìœ„í•´)
          const arrayBuffer = await blob.arrayBuffer();
          console.log('Offscreen: Converting blob to ArrayBuffer, size:', arrayBuffer.byteLength);
          
          // ArrayBufferë¥¼ Uint8Arrayë¡œ ë³€í™˜ í›„ base64ë¡œ ì¸ì½”ë”© (í° ë°°ì—´ ëŒ€ì‘)
          const uint8Array = new Uint8Array(arrayBuffer);
          
          // í° ë°°ì—´ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì²­í¬ ë‹¨ìœ„ë¡œ ë³€í™˜
          const chunkSize = 0x8000; // 32KB chunks
          let base64String = '';
          
          for (let i = 0; i < uint8Array.length; i += chunkSize) {
            const chunk = uint8Array.subarray(i, Math.min(i + chunkSize, uint8Array.length));
            base64String += String.fromCharCode.apply(null, Array.from(chunk));
          }
          
          base64String = btoa(base64String);
          
          console.log('Offscreen: âœ… Encoded to base64, length:', base64String.length);
          logToBackground(`ğŸ“¤ Sending audio data: ${arrayBuffer.byteLength} bytes â†’ ${base64String.length} chars base64`);
          
          sendResponse({ 
            success: true, 
            audioDataBase64: base64String,
            audioDataSize: arrayBuffer.byteLength,
            mimeType: blob.type,
          });
        } catch (error: any) {
          console.error('Offscreen: Error in STOP_RECORDING:', error);
          sendResponse({ error: error.message || 'Unknown error' });
        }
      })();
      return true;

  }
});

async function startRecording(streamId: string): Promise<void> {
  logToBackground('ğŸ”´ Starting recording with streamId:', streamId);
  
  // ì¤‘ë³µ ì •ë¦¬ ë°©ì§€: ì´ë¯¸ ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ì—ì„œ ì •ë¦¬í–ˆì§€ë§Œ, í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš° ëŒ€ë¹„
  if (mediaRecorder && mediaRecorder.state !== 'inactive') {
    logToBackground('âš ï¸ WARNING: mediaRecorder still exists! Cleaning up...');
    try {
      if (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused') {
        mediaRecorder.stop();
        await new Promise(resolve => setTimeout(resolve, 200));
      }
    } catch (e) {
      logToBackground('âš ï¸ Error stopping existing recorder:', e);
    }
    cleanup();
    await new Promise(resolve => setTimeout(resolve, 200));
  }
  
  // ì¶”ê°€ ì•ˆì „ ì •ë¦¬
  if (currentStream) {
    logToBackground('âš ï¸ WARNING: currentStream still exists! Cleaning up...');
    currentStream.getTracks().forEach(track => {
      try {
        track.stop();
      } catch (e) {
        logToBackground('âš ï¸ Error stopping track:', e);
      }
    });
    currentStream = null;
    await new Promise(resolve => setTimeout(resolve, 100));
  }
  
  if (audioContext && audioContext.state !== 'closed') {
    logToBackground('âš ï¸ WARNING: audioContext still exists! Cleaning up...');
    try {
      await audioContext.close();
    } catch (e) {
      logToBackground('âš ï¸ Error closing audio context:', e);
    }
    audioContext = null;
    sourceNode = null;
    await new Promise(resolve => setTimeout(resolve, 100));
  }

  try {
    // getUserMediaë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¼ íšë“
    // ì¬ì‹œë„ ë¡œì§ ì¶”ê°€ (Chrome APIê°€ ì´ì „ ìº¡ì²˜ ìƒíƒœë¥¼ ì™„ì „íˆ í•´ì œí•˜ì§€ ëª»í•  ìˆ˜ ìˆìŒ)
    let stream: MediaStream | null = null;
    let retries = 3;
    let lastError: Error | null = null;
    
    while (retries > 0 && !stream) {
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            mandatory: {
              chromeMediaSource: 'tab',
              chromeMediaSourceId: streamId,
            },
          } as any,
        });
        
        logToBackground('ğŸŸ¢ Got media stream, active:', stream.active);
        logToBackground('ğŸŸ¢ Stream tracks:', stream.getTracks().length);
        currentStream = stream;
        break; // ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ
      } catch (error: any) {
        lastError = error;
        logToBackground(`âš ï¸ Failed to get media stream (attempt ${4 - retries}/3): ${error.message}`);
        
        // "tab capture" ê´€ë ¨ ì—ëŸ¬ì¸ ê²½ìš° ì¬ì‹œë„
        if (error.message.includes('tab capture') || 
            error.message.includes('Cannot capture') ||
            error.name === 'NotAllowedError' ||
            error.name === 'NotFoundError') {
          retries--;
          if (retries > 0) {
            logToBackground(`Retrying in 500ms... (${retries} attempts left)`);
            await new Promise(resolve => setTimeout(resolve, 500));
          }
        } else {
          // ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ë°˜í™˜
          throw error;
        }
      }
    }
    
    if (!stream) {
      const errorMsg = lastError?.message || 'ìŠ¤íŠ¸ë¦¼ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      logToBackground(`âŒ Failed to get media stream after all retries: ${errorMsg}`);
      throw new Error(`Error starting tab capture: ${errorMsg}. ì´ì „ ë…¹ìŒì´ ì™„ì „íˆ ì¢…ë£Œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`);
    }

    // ğŸ”Š ì˜¤ë””ì˜¤ë¥¼ ìŠ¤í”¼ì»¤ë¡œë„ ì¶œë ¥ (ë…¹ìŒí•˜ë©´ì„œ ì†Œë¦¬ ë“¤ë¦¬ê²Œ)
    try {
      audioContext = new AudioContext();
      sourceNode = audioContext.createMediaStreamSource(stream);
      
      // ìŠ¤í”¼ì»¤ë¡œ ì—°ê²°
      sourceNode.connect(audioContext.destination);
      logToBackground('ğŸ”Š Audio connected to speakers');
    } catch (audioError) {
      logToBackground('âš ï¸ Failed to connect audio to speakers:', audioError);
      // ìŠ¤í”¼ì»¤ ì—°ê²° ì‹¤íŒ¨í•´ë„ ë…¹ìŒì€ ê³„ì† ì§„í–‰
    }

    // MediaRecorder ìƒì„± (ë” ì‘ì€ ê°„ê²©ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘)
    const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') 
      ? 'audio/webm;codecs=opus' 
      : 'audio/webm';
    
    console.log('Offscreen: Using mimeType:', mimeType);
    
    mediaRecorder = new MediaRecorder(stream, {
      mimeType: mimeType,
      audioBitsPerSecond: 64000, // 64kbps (STT ì¸ì‹ ê°€ëŠ¥í•œ í’ˆì§ˆ ìœ ì§€)
    });

    audioChunks = [];

    mediaRecorder.ondataavailable = (event) => {
      if (event.data && event.data.size > 0) {
        audioChunks.push(event.data);
        
        // í˜„ì¬ ì´ í¬ê¸° ê³„ì‚°
        const totalSize = audioChunks.reduce((sum, chunk) => sum + chunk.size, 0);
        
        // 24MB ì œí•œ ì²´í¬
        if (totalSize >= MAX_AUDIO_FILE_SIZE) {
          logToBackground(`âš ï¸ Maximum file size reached: ${(totalSize / 1024 / 1024).toFixed(2)}MB (limit: ${(MAX_AUDIO_FILE_SIZE / 1024 / 1024).toFixed(2)}MB)`);
          
          // ìë™ìœ¼ë¡œ ë…¹ìŒ ì •ì§€
          if (mediaRecorder && mediaRecorder.state === 'recording') {
            logToBackground('ğŸ›‘ Auto-stopping recording due to size limit');
            mediaRecorder.stop();
            
            // Backgroundì— ìµœëŒ€ í¬ê¸° ë„ë‹¬ ì•Œë¦¼
            chrome.runtime.sendMessage({
              type: 'RECORDING_MAX_SIZE_REACHED',
              totalSize: totalSize,
            }).catch(() => {});
          }
        }
      }
    };

    mediaRecorder.onstart = () => {
      logToBackground('âœ… MediaRecorder onstart triggered!');
      if (mediaRecorder) {
        logToBackground('ğŸ“Š State:', mediaRecorder.state);
        logToBackground('ğŸ“Š MimeType:', mediaRecorder.mimeType);
      }
      logToBackground('ğŸ“Š Stream active:', stream.active);
      logToBackground('ğŸ“Š Stream tracks:', stream.getTracks().length);
      
      stream.getTracks().forEach((track, i) => {
        logToBackground(`ğŸ“Š Track ${i}: kind=${track.kind}, enabled=${track.enabled}, muted=${track.muted}, readyState=${track.readyState}`);
      });
      
      isManualStop = false;
      finalBlob = null;
      audioChunks = [];
      logToBackground('âœ… Recording initialized, waiting for data...');
    };

    mediaRecorder.onstop = () => {
      console.log('Offscreen: âš ï¸ MediaRecorder stopped (isManualStop:', isManualStop, ')');
      console.log('Offscreen: audioChunks at stop:', audioChunks.length);
      
      // ë…¹ìŒ ë°ì´í„°ë¥¼ ì¦‰ì‹œ Blobìœ¼ë¡œ ì €ì¥
      if (audioChunks.length > 0) {
        finalBlob = new Blob(audioChunks, { type: mimeType });
        console.log('Offscreen: âœ… Saved blob, size:', finalBlob.size);
      } else {
        console.error('Offscreen: âŒ No audio chunks to save!');
      }
    };

    mediaRecorder.onerror = (event: any) => {
      console.error('Offscreen: âŒ MediaRecorder error:', event.error);
      chrome.runtime.sendMessage({
        type: 'RECORDING_ERROR',
        error: event.error?.message || 'Unknown error',
      }).catch(() => {});
    };

    // 100msë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘ (ë” ìì£¼!)
    console.log('Offscreen: Starting MediaRecorder with 100ms timeslice...');
    mediaRecorder.start(100);
    
    console.log('Offscreen: MediaRecorder.start() called');
    if (mediaRecorder) {
      console.log('Offscreen: State after start:', mediaRecorder.state);
    }
    
    // 1ì´ˆ í›„ ìƒíƒœ ì¬í™•ì¸
    setTimeout(() => {
      if (mediaRecorder) {
        console.log('Offscreen: [1sec check] State:', mediaRecorder.state);
        console.log('Offscreen: [1sec check] Chunks collected:', audioChunks.length);
      }
    }, 1000);
  } catch (error) {
    console.error('Offscreen: Error starting recording:', error);
    throw error;
  }
}

async function stopRecording(): Promise<Blob> {
  logToBackground('ğŸ”´ stopRecording called');
  logToBackground('ğŸ”´ mediaRecorder exists:', !!mediaRecorder);
  logToBackground('ğŸ”´ mediaRecorder state:', mediaRecorder?.state);
  logToBackground('ğŸ”´ audioChunks count BEFORE stop:', audioChunks.length);
  
  // í˜„ì¬ chunks ë°±ì—…
  const chunksBeforeStop = [...audioChunks];
  const totalSizeBeforeStop = chunksBeforeStop.reduce((sum, chunk) => sum + chunk.size, 0);
  logToBackground(`ğŸ”´ Total size BEFORE stop: ${(totalSizeBeforeStop / 1024 / 1024).toFixed(2)}MB`);
  
  // 24MB ì œí•œ ì²´í¬
  if (totalSizeBeforeStop > MAX_AUDIO_FILE_SIZE) {
    logToBackground(`âš ï¸ File size exceeds limit: ${(totalSizeBeforeStop / 1024 / 1024).toFixed(2)}MB (limit: ${(MAX_AUDIO_FILE_SIZE / 1024 / 1024).toFixed(2)}MB)`);
    throw new Error(`ë…¹ìŒ íŒŒì¼ í¬ê¸°ê°€ 24MBë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ (${(totalSizeBeforeStop / 1024 / 1024).toFixed(2)}MB). ë…¹ìŒ ì‹œê°„ì„ ì¤„ì—¬ì£¼ì„¸ìš”.`);
  }
  
  return new Promise((resolve, reject) => {
    // mediaRecorderê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
    if (!mediaRecorder) {
      logToBackground('âŒ No mediaRecorder!');
      
      // audioChunksê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì´ë¼ë„ ì‚¬ìš©
      if (chunksBeforeStop.length > 0) {
        logToBackground('âœ… But we have chunks, creating blob anyway');
        const blob = new Blob(chunksBeforeStop, { type: 'audio/webm;codecs=opus' });
        logToBackground('âœ… Emergency blob created, size:', blob.size);
        cleanup();
        resolve(blob);
        return;
      }
      
      cleanup();
      reject(new Error('No recording in progress'));
      return;
    }
    
    const currentState = mediaRecorder.state;
    logToBackground('ğŸ”´ Current state:', currentState);
    
    // inactive ìƒíƒœ: ì´ë¯¸ ì •ì§€ë¨
    if (currentState === 'inactive') {
      logToBackground('âš ï¸ MediaRecorder already inactive');
      
      if (chunksBeforeStop.length === 0) {
        logToBackground('âŒ No chunks!');
        cleanup();
        reject(new Error('No audio data recorded'));
        return;
      }
      
      const blob = new Blob(chunksBeforeStop, { type: 'audio/webm;codecs=opus' });
      logToBackground('âœ… Created blob from chunks, size:', blob.size);
      cleanup();
      resolve(blob);
      return;
    }
    
    // paused ìƒíƒœëŠ” ì´ì œ ì—†ì§€ë§Œ, í˜¹ì‹œ ëª¨ë¥¼ ìƒí™© ëŒ€ë¹„
    if (currentState === 'paused') {
      logToBackground('â¸ï¸ MediaRecorder is paused, resuming before stop...');
      try {
        mediaRecorder.resume();
        logToBackground('âœ… Resumed');
        // resume í›„ ìƒíƒœ ì „í™˜ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸° (Promise ë‚´ë¶€ì´ë¯€ë¡œ Promiseë¡œ ì²˜ë¦¬)
        new Promise<void>((resolve) => {
          setTimeout(() => {
            if (mediaRecorder && mediaRecorder.state === 'paused') {
              logToBackground('âš ï¸ Still paused after resume, forcing stop');
            }
            resolve();
          }, 100);
        }).catch(() => {});
      } catch (e) {
        logToBackground('âš ï¸ Error resuming:', e);
      }
    }

    // ì •ìƒì ìœ¼ë¡œ ì •ì§€
    isManualStop = true;
    
    // stop ì „ì— í˜„ì¬ê¹Œì§€ì˜ chunks ì €ì¥
    const chunksSnapshot = [...audioChunks];
    
    const onStop = () => {
      logToBackground('ğŸŸ¢ onStop handler triggered');
      // stop í›„ ë§ˆì§€ë§‰ chunkê°€ ì¶”ê°€ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í˜„ì¬ chunks ì‚¬ìš©
      const finalChunks = audioChunks.length > chunksSnapshot.length ? audioChunks : chunksSnapshot;
      
      if (finalChunks.length === 0) {
        logToBackground('âŒ No chunks in onStop!');
        cleanup();
        reject(new Error('No audio data recorded'));
        return;
      }
      
      const totalSize = finalChunks.reduce((sum, chunk) => sum + chunk.size, 0);
      
      // chunksë¥¼ ê¹Šì€ ë³µì‚¬ë¡œ ì €ì¥ (cleanup ì „ì—)
      const chunksForBlob = finalChunks.map(chunk => new Blob([chunk], { type: chunk.type || 'audio/webm' }));
      
      const blob = new Blob(chunksForBlob, { type: 'audio/webm;codecs=opus' });
      logToBackground(`âœ…âœ…âœ… Final blob created, size: ${(blob.size / 1024 / 1024).toFixed(2)}MB`);
      
      // 24MB ì œí•œ ìµœì¢… ì²´í¬
      if (blob.size > MAX_AUDIO_FILE_SIZE) {
        logToBackground(`âŒ Blob size exceeds limit: ${(blob.size / 1024 / 1024).toFixed(2)}MB (limit: ${(MAX_AUDIO_FILE_SIZE / 1024 / 1024).toFixed(2)}MB)`);
        cleanup();
        reject(new Error(`ë…¹ìŒ íŒŒì¼ í¬ê¸°ê°€ 24MBë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ (${(blob.size / 1024 / 1024).toFixed(2)}MB). ë…¹ìŒ ì‹œê°„ì„ ì¤„ì—¬ì£¼ì„¸ìš”.`));
        return;
      }
      
      if (blob.size < 1000) {
        logToBackground(`âš ï¸ Blob too small! Expected chunks: ${finalChunks.length}, Total size: ${totalSize}`);
        cleanup();
        reject(new Error(`Blob too small: ${blob.size} bytes. Expected at least 1000 bytes.`));
        return;
      }
      
      // cleanupì€ blobì„ resolveí•œ í›„ì—
      setTimeout(() => {
        cleanup();
      }, 100);
      
      resolve(blob);
    };

    mediaRecorder.onstop = onStop;
    
    try {
      logToBackground('ğŸŸ¢ Calling mediaRecorder.stop()');
      mediaRecorder.stop();
      
      // stop() í›„ ì•½ê°„ì˜ ì§€ì—°ì„ ì£¼ì–´ ë§ˆì§€ë§‰ chunk ìˆ˜ì§‘ ëŒ€ê¸° (ë¡œê·¸ ì œê±°)
    } catch (error) {
      logToBackground('âŒ Error calling stop:', error);
      
      // ì—ëŸ¬ ë°œìƒí•´ë„ chunksê°€ ìˆìœ¼ë©´ blob ìƒì„±
      if (chunksSnapshot.length > 0) {
        logToBackground('âœ… Error but chunks exist, creating blob');
        const blob = new Blob(chunksSnapshot, { type: 'audio/webm;codecs=opus' });
        cleanup();
        resolve(blob);
      } else {
        cleanup();
        reject(error);
      }
    }
  });
}

function cleanup() {
  console.log('Offscreen: Cleaning up...');
  
  // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬
  if (sourceNode) {
    try {
      sourceNode.disconnect();
    } catch (e) {
      console.warn('Error disconnecting source node:', e);
    }
    sourceNode = null;
  }
  
  if (audioContext) {
    try {
      audioContext.close();
    } catch (e) {
      console.warn('Error closing audio context:', e);
    }
    audioContext = null;
  }
  
  // ìŠ¤íŠ¸ë¦¼ ì •ì§€
  if (currentStream) {
    currentStream.getTracks().forEach((track) => {
      try {
        track.stop();
      } catch (e) {
        console.warn('Error stopping track:', e);
      }
    });
    currentStream = null;
  }
  
  mediaRecorder = null;
  audioChunks = [];
  finalBlob = null;
  isManualStop = false;
  
  console.log('Offscreen: Cleanup complete');
}

