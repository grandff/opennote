/// <reference types="chrome"/>

import { MAX_AUDIO_FILE_SIZE, RECORDING_LIMITS } from '@/utils/constants';

let mediaRecorder: MediaRecorder | null = null;
let audioChunks: Blob[] = [];
let audioContext: AudioContext | null = null;
let sourceNode: MediaStreamAudioSourceNode | null = null;
let currentStream: MediaStream | null = null;
let isManualStop: boolean = false;
let finalBlob: Blob | null = null;

// ===== ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ê´€ë ¨ ë³€ìˆ˜ =====
let segmentIndex: number = 0;
let segmentStartTime: number = 0;
let recordingStartTime: number = 0;
let isPremiumUser: boolean = false;
let savedSegments: Array<{ index: number; base64: string; startTime: number; endTime: number; size: number }> = [];

// ===== Realtime APIë¥¼ ìœ„í•œ PCM ì˜¤ë””ì˜¤ ê´€ë ¨ ë³€ìˆ˜ =====
let pcmAudioContext: AudioContext | null = null;
let pcmSourceNode: MediaStreamAudioSourceNode | null = null;
let pcmProcessor: ScriptProcessorNode | null = null;

/**
 * Float32Arrayë¥¼ PCM16 Base64ë¡œ ë³€í™˜
 * OpenAI Realtime API ìš”êµ¬ì‚¬í•­: PCM16 24kHz mono
 */
function float32ToPCM16Base64(float32Array: Float32Array): string {
  // Float32 (-1.0 ~ 1.0) â†’ Int16 (-32768 ~ 32767)
  const pcm16 = new Int16Array(float32Array.length);
  for (let i = 0; i < float32Array.length; i++) {
    const s = Math.max(-1, Math.min(1, float32Array[i]));
    pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
  }
  
  // Int16Array â†’ Uint8Array â†’ Base64
  const uint8 = new Uint8Array(pcm16.buffer);
  let binary = '';
  for (let i = 0; i < uint8.length; i++) {
    binary += String.fromCharCode(uint8[i]);
  }
  return btoa(binary);
}

/**
 * Realtime APIìš© PCM ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
 * Web Audio APIì˜ ScriptProcessorNodeë¥¼ ì‚¬ìš©í•˜ì—¬ PCM16 24kHz mono ë°ì´í„° ì¶”ì¶œ
 */
function startPCMAudioStream(stream: MediaStream): void {
  try {
    // 24kHz AudioContext ìƒì„±
    pcmAudioContext = new AudioContext({ sampleRate: 24000 });
    pcmSourceNode = pcmAudioContext.createMediaStreamSource(stream);
    
    // ScriptProcessorë¡œ PCM ë°ì´í„° ì¶”ì¶œ (bufferSize: 4096 â†’ ì•½ 170ms @ 24kHz)
    pcmProcessor = pcmAudioContext.createScriptProcessor(4096, 1, 1);
    
    pcmProcessor.onaudioprocess = (event) => {
      const float32Data = event.inputBuffer.getChannelData(0);
      const pcm16Base64 = float32ToPCM16Base64(float32Data);
      
      // Backgroundë¡œ PCM ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡
      chrome.runtime.sendMessage({
        type: 'REALTIME_AUDIO_CHUNK',
        audioChunk: pcm16Base64,
        chunkSize: float32Data.length * 2, // PCM16 = 2 bytes per sample
        format: 'pcm16_24khz_mono',
      }).catch(() => {
        // ì „ì†¡ ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ (ë…¹ìŒì— ì˜í–¥ ì—†ìŒ)
      });
    };
    
    // ì—°ê²°: source â†’ processor â†’ destination (destination ì—°ê²° í•„ìˆ˜)
    pcmSourceNode.connect(pcmProcessor);
    pcmProcessor.connect(pcmAudioContext.destination);
    
    logToBackground('ğŸ™ï¸ PCM audio stream started (24kHz mono)');
  } catch (error) {
    console.warn('[Realtime] Error starting PCM audio stream:', error);
    // PCM ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜ê°€ ë‚˜ë„ ë©”ì¸ ë…¹ìŒì— ì˜í–¥ ì—†ìŒ
  }
}

/**
 * Realtime APIìš© PCM ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì •ì§€
 */
function stopPCMAudioStream(): void {
  try {
    if (pcmProcessor) {
      pcmProcessor.disconnect();
      pcmProcessor = null;
    }
    if (pcmSourceNode) {
      pcmSourceNode.disconnect();
      pcmSourceNode = null;
    }
    if (pcmAudioContext && pcmAudioContext.state !== 'closed') {
      pcmAudioContext.close();
      pcmAudioContext = null;
    }
    logToBackground('ğŸ™ï¸ PCM audio stream stopped');
  } catch (error) {
    console.warn('[Realtime] Error stopping PCM audio stream:', error);
  }
}

/**
 * í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ (20ë¶„ë§ˆë‹¤ í˜¸ì¶œ)
 * í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ audioChunksë¥¼ Blobìœ¼ë¡œ ë§Œë“¤ì–´ ì €ì¥í•˜ê³ , audioChunksë¥¼ ë¹„ì›€
 */
async function saveCurrentSegment(): Promise<void> {
  if (audioChunks.length === 0) {
    logToBackground('âš ï¸ No audio chunks to save for segment');
    return;
  }

  const elapsedSeconds = Math.floor((Date.now() - recordingStartTime) / 1000);
  
  // í˜„ì¬ ì²­í¬ë“¤ë¡œ Blob ìƒì„±
  const segmentBlob = new Blob(audioChunks, { type: 'audio/webm;codecs=opus' });
  
  // Blobì„ Base64ë¡œ ë³€í™˜
  const arrayBuffer = await segmentBlob.arrayBuffer();
  const uint8Array = new Uint8Array(arrayBuffer);
  
  const chunkSize = 0x8000;
  let base64String = '';
  for (let i = 0; i < uint8Array.length; i += chunkSize) {
    const chunk = uint8Array.subarray(i, Math.min(i + chunkSize, uint8Array.length));
    base64String += String.fromCharCode.apply(null, Array.from(chunk));
  }
  base64String = btoa(base64String);
  
  // ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
  savedSegments.push({
    index: segmentIndex,
    base64: base64String,
    startTime: segmentStartTime,
    endTime: elapsedSeconds,
    size: arrayBuffer.byteLength,
  });
  
  logToBackground(`ğŸ“¦ Segment ${segmentIndex} saved: ${segmentStartTime}s - ${elapsedSeconds}s (${(arrayBuffer.byteLength / 1024 / 1024).toFixed(2)}MB)`);
  
  // ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ ì¤€ë¹„
  segmentIndex++;
  segmentStartTime = elapsedSeconds;
  
  // ì²­í¬ ë°°ì—´ ë¹„ìš°ê¸° (ìƒˆë¡œìš´ ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘)
  // ì£¼ì˜: MediaRecorderëŠ” ê³„ì† ì‹¤í–‰ ì¤‘ì´ë¯€ë¡œ ìƒˆ ì²­í¬ëŠ” ê³„ì† ì¶”ê°€ë¨
  audioChunks = [];
  
  // Backgroundì— ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ ì™„ë£Œ ì•Œë¦¼
  chrome.runtime.sendMessage({
    type: 'SEGMENT_SAVED',
    segmentIndex: segmentIndex - 1,
    totalSegments: savedSegments.length,
    elapsedSeconds,
  }).catch(() => {});
}

/**
 * ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• ì´ í•„ìš”í•œì§€ í™•ì¸ (20ë¶„ë§ˆë‹¤)
 */
function shouldSplitSegment(): boolean {
  if (!isPremiumUser) return false;
  
  const elapsedSeconds = Math.floor((Date.now() - recordingStartTime) / 1000);
  const currentSegmentDuration = elapsedSeconds - segmentStartTime;
  
  return currentSegmentDuration >= RECORDING_LIMITS.SEGMENT_DURATION;
}

// ë¡œê·¸ë¥¼ Backgroundë¡œ ì „ì†¡í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
function logToBackground(message: string, data?: any) {
  const fullMessage = data !== undefined ? `${message} ${JSON.stringify(data)}` : message;
  console.log(fullMessage);
  chrome.runtime.sendMessage({
    type: 'OFFSCREEN_LOG',
    message: fullMessage,
    data: data,
  }).catch(() => {});
}

logToBackground('ğŸŸ¢ Offscreen document loaded');

// Backgroundì— ì¤€ë¹„ ì™„ë£Œ ì‹ í˜¸
setTimeout(() => {
  logToBackground('ğŸŸ¢ Offscreen document fully loaded and ready');
}, 100);

// Backgroundë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
chrome.runtime.onMessage.addListener((message, _sender, sendResponse) => {
  console.log('Offscreen received message:', message);

  switch (message.type) {
    case 'CLEANUP':
      console.log('Offscreen: Received CLEANUP message');
      cleanup();
      sendResponse({ success: true });
      break;

    case 'SET_PREMIUM_USER':
      isPremiumUser = message.isPremium === true;
      logToBackground(`ğŸ‘¤ Premium user: ${isPremiumUser}`);
      sendResponse({ success: true });
      break;

    case 'START_RECORDING':
      (async () => {
        logToBackground('ğŸ”´ START_RECORDING message received');
        
        // ì„¸ê·¸ë¨¼íŠ¸ ê´€ë ¨ ì´ˆê¸°í™”
        segmentIndex = 0;
        segmentStartTime = 0;
        recordingStartTime = Date.now();
        savedSegments = [];
        
        // isPremiumUserëŠ” START_RECORDING ì „ì— SET_PREMIUM_USERë¡œ ì„¤ì •ë¨
        if (message.isPremium !== undefined) {
          isPremiumUser = message.isPremium === true;
        }
        logToBackground(`ğŸ‘¤ Recording as ${isPremiumUser ? 'premium' : 'free'} user`);
        
        // ì´ì „ ë…¹ìŒì´ ìˆìœ¼ë©´ ì™„ì „íˆ ì •ë¦¬
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
          logToBackground('âš ï¸ Previous recording still active, cleaning up...');
          try {
            const prevState = mediaRecorder.state;
            logToBackground(`âš ï¸ Previous recorder state: ${prevState}`);
            
            if (prevState === 'recording' || prevState === 'paused') {
              logToBackground('âš ï¸ Stopping previous recorder...');
              mediaRecorder.stop();
              // stop ì™„ë£Œ ëŒ€ê¸°
              await new Promise(resolve => setTimeout(resolve, 200));
            }
          } catch (e) {
            logToBackground('âš ï¸ Error stopping previous recorder:', e);
          }
          
          // ì™„ì „ ì •ë¦¬
          cleanup();
          // ì •ë¦¬ ì™„ë£Œ ëŒ€ê¸°
          await new Promise(resolve => setTimeout(resolve, 300));
        }
        
        // ìŠ¤íŠ¸ë¦¼ì´ ë‚¨ì•„ìˆìœ¼ë©´ ì •ë¦¬
        if (currentStream) {
          logToBackground('âš ï¸ Cleaning up existing stream...');
          currentStream.getTracks().forEach(track => {
            try {
              track.stop();
            } catch (e) {
              logToBackground('âš ï¸ Error stopping track:', e);
            }
          });
          currentStream = null;
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        
        // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ê°€ ë‚¨ì•„ìˆìœ¼ë©´ ì •ë¦¬
        if (audioContext && audioContext.state !== 'closed') {
          logToBackground('âš ï¸ Closing existing audio context...');
          try {
            await audioContext.close();
          } catch (e) {
            logToBackground('âš ï¸ Error closing audio context:', e);
          }
          audioContext = null;
          sourceNode = null;
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        
        try {
          logToBackground('ğŸŸ¢ Starting new recording...');
          await startRecording(message.streamId);
          sendResponse({ success: true });
        } catch (error: any) {
          console.error('Offscreen: âŒ Error starting recording:', error);
          logToBackground(`âŒ Error: ${error.message || 'Unknown error'}`);
          sendResponse({ error: error.message || 'Error starting recording' });
        }
      })();
      return true;

    case 'STOP_RECORDING':
      (async () => {
        try {
          const blob = await stopRecording();
          if (!blob || blob.size === 0) {
            sendResponse({ error: 'No audio data recorded' });
            return;
          }
          
          // Blobì„ ArrayBufferë¡œ ë³€í™˜ í›„ base64ë¡œ ì¸ì½”ë”© (Chrome message passingì„ ìœ„í•´)
          const arrayBuffer = await blob.arrayBuffer();
          console.log('Offscreen: Converting blob to ArrayBuffer, size:', arrayBuffer.byteLength);
          
          // ArrayBufferë¥¼ Uint8Arrayë¡œ ë³€í™˜ í›„ base64ë¡œ ì¸ì½”ë”© (í° ë°°ì—´ ëŒ€ì‘)
          const uint8Array = new Uint8Array(arrayBuffer);
          
          // í° ë°°ì—´ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì²­í¬ ë‹¨ìœ„ë¡œ ë³€í™˜
          const chunkSize = 0x8000; // 32KB chunks
          let base64String = '';
          
          for (let i = 0; i < uint8Array.length; i += chunkSize) {
            const chunk = uint8Array.subarray(i, Math.min(i + chunkSize, uint8Array.length));
            base64String += String.fromCharCode.apply(null, Array.from(chunk));
          }
          
          base64String = btoa(base64String);
          
          console.log('Offscreen: âœ… Encoded to base64, length:', base64String.length);
          logToBackground(`ğŸ“¤ Sending audio data: ${arrayBuffer.byteLength} bytes â†’ ${base64String.length} chars base64`);
          
          // ì„¸ê·¸ë¨¼íŠ¸ê°€ ìˆëŠ” ê²½ìš° (ìœ ë£Œ ì‚¬ìš©ì, 20ë¶„ ì´ìƒ ë…¹ìŒ)
          const elapsedSeconds = Math.floor((Date.now() - recordingStartTime) / 1000);
          
          // ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€ (í˜„ì¬ ë¸”ë¡­)
          if (isPremiumUser && savedSegments.length > 0) {
            savedSegments.push({
              index: segmentIndex,
              base64: base64String,
              startTime: segmentStartTime,
              endTime: elapsedSeconds,
              size: arrayBuffer.byteLength,
            });
            
            logToBackground(`ğŸ“¦ Total segments: ${savedSegments.length}`);
            
            sendResponse({ 
              success: true, 
              audioDataBase64: base64String,
              audioDataSize: arrayBuffer.byteLength,
              mimeType: blob.type,
              segments: savedSegments,
              totalSegments: savedSegments.length,
            });
          } else {
            // ë‹¨ì¼ íŒŒì¼ (ë¬´ë£Œ ì‚¬ìš©ì ë˜ëŠ” 20ë¶„ ì´í•˜)
            sendResponse({ 
              success: true, 
              audioDataBase64: base64String,
              audioDataSize: arrayBuffer.byteLength,
              mimeType: blob.type,
            });
          }
        } catch (error: any) {
          console.error('Offscreen: Error in STOP_RECORDING:', error);
          sendResponse({ error: error.message || 'Unknown error' });
        }
      })();
      return true;

    case 'SAVE_SEGMENT':
      // ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ ìš”ì²­ (20ë¶„ë§ˆë‹¤ í˜¸ì¶œë¨)
      (async () => {
        try {
          await saveCurrentSegment();
          sendResponse({ success: true, segmentIndex });
        } catch (error: any) {
          console.error('Offscreen: Error saving segment:', error);
          sendResponse({ error: error.message });
        }
      })();
      return true;

  }
});

async function startRecording(streamId: string): Promise<void> {
  logToBackground('ğŸ”´ Starting recording with streamId:', streamId);
  
  // ì¤‘ë³µ ì •ë¦¬ ë°©ì§€: ì´ë¯¸ ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ì—ì„œ ì •ë¦¬í–ˆì§€ë§Œ, í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš° ëŒ€ë¹„
  if (mediaRecorder && mediaRecorder.state !== 'inactive') {
    logToBackground('âš ï¸ WARNING: mediaRecorder still exists! Cleaning up...');
    try {
      if (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused') {
        mediaRecorder.stop();
        await new Promise(resolve => setTimeout(resolve, 200));
      }
    } catch (e) {
      logToBackground('âš ï¸ Error stopping existing recorder:', e);
    }
    cleanup();
    await new Promise(resolve => setTimeout(resolve, 200));
  }
  
  // ì¶”ê°€ ì•ˆì „ ì •ë¦¬
  if (currentStream) {
    logToBackground('âš ï¸ WARNING: currentStream still exists! Cleaning up...');
    currentStream.getTracks().forEach(track => {
      try {
        track.stop();
      } catch (e) {
        logToBackground('âš ï¸ Error stopping track:', e);
      }
    });
    currentStream = null;
    await new Promise(resolve => setTimeout(resolve, 100));
  }
  
  if (audioContext && audioContext.state !== 'closed') {
    logToBackground('âš ï¸ WARNING: audioContext still exists! Cleaning up...');
    try {
      await audioContext.close();
    } catch (e) {
      logToBackground('âš ï¸ Error closing audio context:', e);
    }
    audioContext = null;
    sourceNode = null;
    await new Promise(resolve => setTimeout(resolve, 100));
  }

  try {
    // getUserMediaë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¼ íšë“
    // ì¬ì‹œë„ ë¡œì§ ì¶”ê°€ (Chrome APIê°€ ì´ì „ ìº¡ì²˜ ìƒíƒœë¥¼ ì™„ì „íˆ í•´ì œí•˜ì§€ ëª»í•  ìˆ˜ ìˆìŒ)
    let stream: MediaStream | null = null;
    let retries = 3;
    let lastError: Error | null = null;
    
    while (retries > 0 && !stream) {
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            mandatory: {
              chromeMediaSource: 'tab',
              chromeMediaSourceId: streamId,
            },
          } as any,
        });
        
        logToBackground('ğŸŸ¢ Got media stream, active:', stream.active);
        logToBackground('ğŸŸ¢ Stream tracks:', stream.getTracks().length);
        currentStream = stream;
        break; // ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ
      } catch (error: any) {
        lastError = error;
        logToBackground(`âš ï¸ Failed to get media stream (attempt ${4 - retries}/3): ${error.message}`);
        
        // "tab capture" ê´€ë ¨ ì—ëŸ¬ì¸ ê²½ìš° ì¬ì‹œë„
        if (error.message.includes('tab capture') || 
            error.message.includes('Cannot capture') ||
            error.name === 'NotAllowedError' ||
            error.name === 'NotFoundError') {
          retries--;
          if (retries > 0) {
            logToBackground(`Retrying in 500ms... (${retries} attempts left)`);
            await new Promise(resolve => setTimeout(resolve, 500));
          }
        } else {
          // ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ë°˜í™˜
          throw error;
        }
      }
    }
    
    if (!stream) {
      const errorMsg = lastError?.message || 'ìŠ¤íŠ¸ë¦¼ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      logToBackground(`âŒ Failed to get media stream after all retries: ${errorMsg}`);
      throw new Error(`Error starting tab capture: ${errorMsg}. ì´ì „ ë…¹ìŒì´ ì™„ì „íˆ ì¢…ë£Œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`);
    }

    // ğŸ”Š ì˜¤ë””ì˜¤ë¥¼ ìŠ¤í”¼ì»¤ë¡œë„ ì¶œë ¥ (ë…¹ìŒí•˜ë©´ì„œ ì†Œë¦¬ ë“¤ë¦¬ê²Œ)
    try {
      audioContext = new AudioContext();
      sourceNode = audioContext.createMediaStreamSource(stream);
      
      // ìŠ¤í”¼ì»¤ë¡œ ì—°ê²°
      sourceNode.connect(audioContext.destination);
      logToBackground('ğŸ”Š Audio connected to speakers');
    } catch (audioError) {
      logToBackground('âš ï¸ Failed to connect audio to speakers:', audioError);
      // ìŠ¤í”¼ì»¤ ì—°ê²° ì‹¤íŒ¨í•´ë„ ë…¹ìŒì€ ê³„ì† ì§„í–‰
    }

    // ===== Realtime APIìš© PCM ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ =====
    // ë³„ë„ì˜ AudioContextë¥¼ ì‚¬ìš©í•˜ì—¬ 24kHz PCM ë°ì´í„° ì¶”ì¶œ
    startPCMAudioStream(stream);

    // MediaRecorder ìƒì„± (ë” ì‘ì€ ê°„ê²©ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘)
    const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') 
      ? 'audio/webm;codecs=opus' 
      : 'audio/webm';
    
    console.log('Offscreen: Using mimeType:', mimeType);
    
    mediaRecorder = new MediaRecorder(stream, {
      mimeType: mimeType,
      audioBitsPerSecond: 64000, // 64kbps (STT ì¸ì‹ ê°€ëŠ¥í•œ í’ˆì§ˆ ìœ ì§€)
    });

    audioChunks = [];

    mediaRecorder.ondataavailable = async (event) => {
      if (event.data && event.data.size > 0) {
        audioChunks.push(event.data);
        
        // í˜„ì¬ ì´ í¬ê¸° ê³„ì‚°
        const totalSize = audioChunks.reduce((sum, chunk) => sum + chunk.size, 0);
        
        // 24MB ì œí•œ ì²´í¬
        if (totalSize >= MAX_AUDIO_FILE_SIZE) {
          logToBackground(`âš ï¸ Maximum file size reached: ${(totalSize / 1024 / 1024).toFixed(2)}MB (limit: ${(MAX_AUDIO_FILE_SIZE / 1024 / 1024).toFixed(2)}MB)`);
          
          // ìë™ìœ¼ë¡œ ë…¹ìŒ ì •ì§€
          if (mediaRecorder && mediaRecorder.state === 'recording') {
            logToBackground('ğŸ›‘ Auto-stopping recording due to size limit');
            mediaRecorder.stop();
            
            // Backgroundì— ìµœëŒ€ í¬ê¸° ë„ë‹¬ ì•Œë¦¼
            chrome.runtime.sendMessage({
              type: 'RECORDING_MAX_SIZE_REACHED',
              totalSize: totalSize,
            }).catch(() => {});
          }
        }
        
        // ===== ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì²´í¬ (ìœ ë£Œ ì‚¬ìš©ì, 20ë¶„ë§ˆë‹¤) =====
        if (shouldSplitSegment()) {
          logToBackground('ğŸ“¦ Splitting segment at 20 minutes...');
          try {
            await saveCurrentSegment();
          } catch (error) {
            console.warn('[Segment] Error saving segment:', error);
            // ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ ì‹¤íŒ¨í•´ë„ ë…¹ìŒì€ ê³„ì†ë¨
          }
        }
        
        // Note: Realtime APIìš© PCM ì˜¤ë””ì˜¤ëŠ” ë³„ë„ì˜ ScriptProcessorNodeì—ì„œ ì²˜ë¦¬ë¨
      }
    };

    mediaRecorder.onstart = () => {
      logToBackground('âœ… MediaRecorder onstart triggered!');
      if (mediaRecorder) {
        logToBackground('ğŸ“Š State:', mediaRecorder.state);
        logToBackground('ğŸ“Š MimeType:', mediaRecorder.mimeType);
      }
      logToBackground('ğŸ“Š Stream active:', stream.active);
      logToBackground('ğŸ“Š Stream tracks:', stream.getTracks().length);
      
      stream.getTracks().forEach((track, i) => {
        logToBackground(`ğŸ“Š Track ${i}: kind=${track.kind}, enabled=${track.enabled}, muted=${track.muted}, readyState=${track.readyState}`);
      });
      
      isManualStop = false;
      finalBlob = null;
      audioChunks = [];
      logToBackground('âœ… Recording initialized, waiting for data...');
    };

    mediaRecorder.onstop = () => {
      console.log('Offscreen: âš ï¸ MediaRecorder stopped (isManualStop:', isManualStop, ')');
      console.log('Offscreen: audioChunks at stop:', audioChunks.length);
      
      // ë…¹ìŒ ë°ì´í„°ë¥¼ ì¦‰ì‹œ Blobìœ¼ë¡œ ì €ì¥
      if (audioChunks.length > 0) {
        finalBlob = new Blob(audioChunks, { type: mimeType });
        console.log('Offscreen: âœ… Saved blob, size:', finalBlob.size);
      } else {
        console.error('Offscreen: âŒ No audio chunks to save!');
      }
    };

    mediaRecorder.onerror = (event: any) => {
      console.error('Offscreen: âŒ MediaRecorder error:', event.error);
      chrome.runtime.sendMessage({
        type: 'RECORDING_ERROR',
        error: event.error?.message || 'Unknown error',
      }).catch(() => {});
    };

    // 100msë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘ (ë” ìì£¼!)
    console.log('Offscreen: Starting MediaRecorder with 100ms timeslice...');
    mediaRecorder.start(100);
    
    console.log('Offscreen: MediaRecorder.start() called');
    if (mediaRecorder) {
      console.log('Offscreen: State after start:', mediaRecorder.state);
    }
    
    // 1ì´ˆ í›„ ìƒíƒœ ì¬í™•ì¸
    setTimeout(() => {
      if (mediaRecorder) {
        console.log('Offscreen: [1sec check] State:', mediaRecorder.state);
        console.log('Offscreen: [1sec check] Chunks collected:', audioChunks.length);
      }
    }, 1000);
  } catch (error) {
    console.error('Offscreen: Error starting recording:', error);
    throw error;
  }
}

async function stopRecording(): Promise<Blob> {
  logToBackground('ğŸ”´ stopRecording called');
  logToBackground('ğŸ”´ mediaRecorder exists:', !!mediaRecorder);
  logToBackground('ğŸ”´ mediaRecorder state:', mediaRecorder?.state);
  logToBackground('ğŸ”´ audioChunks count BEFORE stop:', audioChunks.length);
  
  // í˜„ì¬ chunks ë°±ì—…
  const chunksBeforeStop = [...audioChunks];
  const totalSizeBeforeStop = chunksBeforeStop.reduce((sum, chunk) => sum + chunk.size, 0);
  logToBackground(`ğŸ”´ Total size BEFORE stop: ${(totalSizeBeforeStop / 1024 / 1024).toFixed(2)}MB`);
  
  // 24MB ì œí•œ ì²´í¬
  if (totalSizeBeforeStop > MAX_AUDIO_FILE_SIZE) {
    logToBackground(`âš ï¸ File size exceeds limit: ${(totalSizeBeforeStop / 1024 / 1024).toFixed(2)}MB (limit: ${(MAX_AUDIO_FILE_SIZE / 1024 / 1024).toFixed(2)}MB)`);
    throw new Error(`ë…¹ìŒ íŒŒì¼ í¬ê¸°ê°€ 24MBë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ (${(totalSizeBeforeStop / 1024 / 1024).toFixed(2)}MB). ë…¹ìŒ ì‹œê°„ì„ ì¤„ì—¬ì£¼ì„¸ìš”.`);
  }
  
  return new Promise((resolve, reject) => {
    // mediaRecorderê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
    if (!mediaRecorder) {
      logToBackground('âŒ No mediaRecorder!');
      
      // audioChunksê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì´ë¼ë„ ì‚¬ìš©
      if (chunksBeforeStop.length > 0) {
        logToBackground('âœ… But we have chunks, creating blob anyway');
        const blob = new Blob(chunksBeforeStop, { type: 'audio/webm;codecs=opus' });
        logToBackground('âœ… Emergency blob created, size:', blob.size);
        cleanup();
        resolve(blob);
        return;
      }
      
      cleanup();
      reject(new Error('No recording in progress'));
      return;
    }
    
    const currentState = mediaRecorder.state;
    logToBackground('ğŸ”´ Current state:', currentState);
    
    // inactive ìƒíƒœ: ì´ë¯¸ ì •ì§€ë¨
    if (currentState === 'inactive') {
      logToBackground('âš ï¸ MediaRecorder already inactive');
      
      if (chunksBeforeStop.length === 0) {
        logToBackground('âŒ No chunks!');
        cleanup();
        reject(new Error('No audio data recorded'));
        return;
      }
      
      const blob = new Blob(chunksBeforeStop, { type: 'audio/webm;codecs=opus' });
      logToBackground('âœ… Created blob from chunks, size:', blob.size);
      cleanup();
      resolve(blob);
      return;
    }
    
    // paused ìƒíƒœëŠ” ì´ì œ ì—†ì§€ë§Œ, í˜¹ì‹œ ëª¨ë¥¼ ìƒí™© ëŒ€ë¹„
    if (currentState === 'paused') {
      logToBackground('â¸ï¸ MediaRecorder is paused, resuming before stop...');
      try {
        mediaRecorder.resume();
        logToBackground('âœ… Resumed');
        // resume í›„ ìƒíƒœ ì „í™˜ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸° (Promise ë‚´ë¶€ì´ë¯€ë¡œ Promiseë¡œ ì²˜ë¦¬)
        new Promise<void>((resolve) => {
          setTimeout(() => {
            if (mediaRecorder && mediaRecorder.state === 'paused') {
              logToBackground('âš ï¸ Still paused after resume, forcing stop');
            }
            resolve();
          }, 100);
        }).catch(() => {});
      } catch (e) {
        logToBackground('âš ï¸ Error resuming:', e);
      }
    }

    // ì •ìƒì ìœ¼ë¡œ ì •ì§€
    isManualStop = true;
    
    // stop ì „ì— í˜„ì¬ê¹Œì§€ì˜ chunks ì €ì¥
    const chunksSnapshot = [...audioChunks];
    
    const onStop = () => {
      logToBackground('ğŸŸ¢ onStop handler triggered');
      // stop í›„ ë§ˆì§€ë§‰ chunkê°€ ì¶”ê°€ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í˜„ì¬ chunks ì‚¬ìš©
      const finalChunks = audioChunks.length > chunksSnapshot.length ? audioChunks : chunksSnapshot;
      
      if (finalChunks.length === 0) {
        logToBackground('âŒ No chunks in onStop!');
        cleanup();
        reject(new Error('No audio data recorded'));
        return;
      }
      
      const totalSize = finalChunks.reduce((sum, chunk) => sum + chunk.size, 0);
      
      // chunksë¥¼ ê¹Šì€ ë³µì‚¬ë¡œ ì €ì¥ (cleanup ì „ì—)
      const chunksForBlob = finalChunks.map(chunk => new Blob([chunk], { type: chunk.type || 'audio/webm' }));
      
      const blob = new Blob(chunksForBlob, { type: 'audio/webm;codecs=opus' });
      logToBackground(`âœ…âœ…âœ… Final blob created, size: ${(blob.size / 1024 / 1024).toFixed(2)}MB`);
      
      // 24MB ì œí•œ ìµœì¢… ì²´í¬
      if (blob.size > MAX_AUDIO_FILE_SIZE) {
        logToBackground(`âŒ Blob size exceeds limit: ${(blob.size / 1024 / 1024).toFixed(2)}MB (limit: ${(MAX_AUDIO_FILE_SIZE / 1024 / 1024).toFixed(2)}MB)`);
        cleanup();
        reject(new Error(`ë…¹ìŒ íŒŒì¼ í¬ê¸°ê°€ 24MBë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ (${(blob.size / 1024 / 1024).toFixed(2)}MB). ë…¹ìŒ ì‹œê°„ì„ ì¤„ì—¬ì£¼ì„¸ìš”.`));
        return;
      }
      
      if (blob.size < 1000) {
        logToBackground(`âš ï¸ Blob too small! Expected chunks: ${finalChunks.length}, Total size: ${totalSize}`);
        cleanup();
        reject(new Error(`Blob too small: ${blob.size} bytes. Expected at least 1000 bytes.`));
        return;
      }
      
      // cleanupì€ blobì„ resolveí•œ í›„ì—
      setTimeout(() => {
        cleanup();
      }, 100);
      
      resolve(blob);
    };

    mediaRecorder.onstop = onStop;
    
    try {
      logToBackground('ğŸŸ¢ Calling mediaRecorder.stop()');
      mediaRecorder.stop();
      
      // stop() í›„ ì•½ê°„ì˜ ì§€ì—°ì„ ì£¼ì–´ ë§ˆì§€ë§‰ chunk ìˆ˜ì§‘ ëŒ€ê¸° (ë¡œê·¸ ì œê±°)
    } catch (error) {
      logToBackground('âŒ Error calling stop:', error);
      
      // ì—ëŸ¬ ë°œìƒí•´ë„ chunksê°€ ìˆìœ¼ë©´ blob ìƒì„±
      if (chunksSnapshot.length > 0) {
        logToBackground('âœ… Error but chunks exist, creating blob');
        const blob = new Blob(chunksSnapshot, { type: 'audio/webm;codecs=opus' });
        cleanup();
        resolve(blob);
      } else {
        cleanup();
        reject(error);
      }
    }
  });
}

function cleanup() {
  console.log('Offscreen: Cleaning up...');
  
  // ===== Realtime APIìš© PCM ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ =====
  stopPCMAudioStream();
  
  // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ (ìŠ¤í”¼ì»¤ ì¶œë ¥ìš©)
  if (sourceNode) {
    try {
      sourceNode.disconnect();
    } catch (e) {
      console.warn('Error disconnecting source node:', e);
    }
    sourceNode = null;
  }
  
  if (audioContext) {
    try {
      audioContext.close();
    } catch (e) {
      console.warn('Error closing audio context:', e);
    }
    audioContext = null;
  }
  
  // ìŠ¤íŠ¸ë¦¼ ì •ì§€
  if (currentStream) {
    currentStream.getTracks().forEach((track) => {
      try {
        track.stop();
      } catch (e) {
        console.warn('Error stopping track:', e);
      }
    });
    currentStream = null;
  }
  
  mediaRecorder = null;
  audioChunks = [];
  finalBlob = null;
  isManualStop = false;
  
  console.log('Offscreen: Cleanup complete');
}

